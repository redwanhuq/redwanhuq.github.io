<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Machine Made PhD (Posts about machine learning)</title><link>https://redwanhuq.github.io/</link><description></description><atom:link href="https://redwanhuq.github.io/categories/machine-learning.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Thu, 16 Mar 2017 14:23:57 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Applying k-means clustering to flow cytometry analysis</title><link>https://redwanhuq.github.io/posts/k-means_clustering/</link><dc:creator>Redwan Huq</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Is it possible for a machine to group together similar data on its own? Absolutely—this is what clustering algorithms are all about. These algorithms fall under a branch of machine learning called &lt;strong&gt;unsupervised learning&lt;/strong&gt;. In this branch, we give a machine an &lt;em&gt;unlabeled&lt;/em&gt; training set containing data regarding the features but not the classes. Algorithms are left to their own devices to discover the underlying structure concealed within the data. This is in stark contrast to &lt;a href="http://machinemadephd.com/posts/building-logistic-regression/"&gt;supervised learning&lt;/a&gt;, where the correct answers are available and utilized to train a predictive model.&lt;/p&gt;
&lt;p&gt;In this post, we'll not only learn about an algorithm called &lt;strong&gt;$k$-means clustering&lt;/strong&gt;, but construct one from scratch. Additionally, we'll apply this algorithm to automate an aspect of a widely used life sciences technique called &lt;strong&gt;flow cytometry&lt;/strong&gt;.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://redwanhuq.github.io/posts/k-means_clustering/"&gt;Read more…&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>clustering</category><category>flow cytometry</category><category>k-means</category><category>machine learning</category><category>python</category><category>unsupervised learning</category><guid>https://redwanhuq.github.io/posts/k-means_clustering/</guid><pubDate>Thu, 16 Mar 2017 14:00:00 GMT</pubDate></item><item><title>Building a logistic regression classifier from the ground up</title><link>https://redwanhuq.github.io/posts/building-logistic-regression/</link><dc:creator>Redwan Huq</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The logistic regression classifier is a widely used machine learning model that predicts the group or category that an observation belongs to. When implementing this model, most people rely on &lt;a href="http://scikit-learn.org/stable/"&gt;some package&lt;/a&gt; or API: just hand over a dataset, pick a few parameters and out come the predictions. However, I'm not a fan of using black boxes without first understanding what's going on inside. In fact, lifting the hood on this classifier provides a segue to more complex models such as neural networks. Therefore, this post will explore the methodology behind logistic regression classifiers and walk through how to construct one from scratch.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://redwanhuq.github.io/posts/building-logistic-regression/"&gt;Read more…&lt;/a&gt; (16 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>classification</category><category>gradient descent</category><category>logistic regression</category><category>machine learning</category><category>python</category><category>supervised learning</category><guid>https://redwanhuq.github.io/posts/building-logistic-regression/</guid><pubDate>Mon, 13 Feb 2017 16:00:00 GMT</pubDate></item><item><title>What exactly is data science?</title><link>https://redwanhuq.github.io/posts/what-is-data-science/</link><dc:creator>Redwan Huq</dc:creator><description>&lt;div&gt;&lt;p&gt;I figured I'd focus my first post on a broad topic and what better way than to discuss what this blog will revolve around: data science! Actually, when I talk to people about data science, I usually get blank stares, maybe a head nod or two, and if I'm lucky, someone will ask "is that related to big data?". This is understandable because data science is an emerging field—practically everyone has their own definition, so I'd like to begin by sharing mine.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://redwanhuq.github.io/posts/what-is-data-science/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>data analytics</category><category>data science</category><category>machine learning</category><guid>https://redwanhuq.github.io/posts/what-is-data-science/</guid><pubDate>Mon, 16 Jan 2017 16:00:00 GMT</pubDate></item></channel></rss>