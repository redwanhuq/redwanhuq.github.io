<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>In Machines We Trust (Posts about machine learning)</title><link>https://redwanhuq.github.io/</link><description></description><atom:link rel="self" type="application/rss+xml" href="https://redwanhuq.github.io/categories/machine-learning.xml"></atom:link><language>en</language><lastBuildDate>Thu, 11 May 2017 22:42:38 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Applying k-means clustering to flow cytometry analysis</title><link>https://redwanhuq.github.io/posts/k-means_clustering/</link><dc:creator>Redwan Huq</dc:creator><description>&lt;div&gt;&lt;style type="text/css"&gt;
div.prompt {
	display: none;
}


&lt;/style&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Is it possible for a machine to group together similar data on its own? Absolutely—this is what clustering algorithms are all about. These algorithms fall under a branch of machine learning called &lt;strong&gt;unsupervised learning&lt;/strong&gt;. In this branch, we give a machine an &lt;em&gt;unlabeled&lt;/em&gt; training set containing data regarding the features but not the classes. Algorithms are left to their own devices to discover the underlying structure concealed within the data. This is in stark contrast to &lt;a href="http://machinemadephd.com/posts/building-logistic-regression/"&gt;supervised learning&lt;/a&gt;, where the correct answers are available and utilized to train a predictive model.&lt;/p&gt;
&lt;p&gt;In this post, I'd like to introduce an algorithm called &lt;strong&gt;$k$-means clustering&lt;/strong&gt; and also construct one from scratch. Additionally, I'll demonstrate how this algorithm can be used automate an aspect of a widely used life sciences technique called &lt;strong&gt;flow cytometry&lt;/strong&gt;.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://redwanhuq.github.io/posts/k-means_clustering/"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>clustering</category><category>k-means</category><category>machine learning</category><category>python</category><category>tutorial</category><category>unsupervised learning</category><guid>https://redwanhuq.github.io/posts/k-means_clustering/</guid><pubDate>Thu, 16 Mar 2017 14:00:00 GMT</pubDate></item><item><title>Building a logistic regression classifier from the ground up</title><link>https://redwanhuq.github.io/posts/building-logistic-regression/</link><dc:creator>Redwan Huq</dc:creator><description>&lt;div&gt;&lt;style type="text/css"&gt;
div.prompt {
	display: none;
}


&lt;/style&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The logistic regression classifier is a widely used machine learning model that predicts the group or category that an observation belongs to. When implementing this model, most people rely on some package or API: just hand over a dataset and out come the predictions. However, I'm not a fan of using black boxes without first understanding what's going on inside. In fact, lifting the hood on this classifier provides a segue to more complex models such as neural networks. Therefore, in this post, I'd like to explore the methodology behind logistic regression classifiers and walk through how to construct one from scratch.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://redwanhuq.github.io/posts/building-logistic-regression/"&gt;Read more…&lt;/a&gt; (15 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>classification</category><category>gradient descent</category><category>logistic regression</category><category>machine learning</category><category>python</category><category>supervised learning</category><category>tutorial</category><guid>https://redwanhuq.github.io/posts/building-logistic-regression/</guid><pubDate>Mon, 13 Feb 2017 16:00:00 GMT</pubDate></item><item><title>What exactly is data science?</title><link>https://redwanhuq.github.io/posts/what-is-data-science/</link><dc:creator>Redwan Huq</dc:creator><description>&lt;div&gt;&lt;p&gt;I figured I'd focus my first post on a broad topic and what better way than to discuss what this blog will revolve around: data science! Actually, when I talk to most people about data science, I usually get blank stares. This is understandable because data science is an emerging field—practically everyone has their own definition, so I'd like to begin by sharing mine.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://redwanhuq.github.io/posts/what-is-data-science/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>data analytics</category><category>data science</category><category>machine learning</category><guid>https://redwanhuq.github.io/posts/what-is-data-science/</guid><pubDate>Mon, 16 Jan 2017 16:00:00 GMT</pubDate></item></channel></rss>