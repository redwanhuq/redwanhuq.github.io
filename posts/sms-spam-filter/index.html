<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Using natural language processing to build a spam filter for text messages | In Machines We Trust</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#0078D7">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://redwanhuq.github.io/posts/sms-spam-filter/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css">
<meta name="author" content="Redwan Huq">
<link rel="prev" href="../mushroom-classification/" title="Determining whether a mushroom is edible with machine learning" type="text/html">
<meta property="og:site_name" content="In Machines We Trust">
<meta property="og:title" content="Using natural language processing to build a spam filter for text mess">
<meta property="og:url" content="https://redwanhuq.github.io/posts/sms-spam-filter/">
<meta property="og:description" content="div.prompt {
	display: none;
}

div.rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {
  font-size: 16px;
  border: 1px solid black;
}








After watching the film Arriv">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-05-30T08:00:00-05:00">
<meta property="article:tag" content="classification">
<meta property="article:tag" content="learning curves">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="n-grams">
<meta property="article:tag" content="natural language processing">
<meta property="article:tag" content="nested cross-validation">
<meta property="article:tag" content="nltk">
<meta property="article:tag" content="scikit-learn">
<meta property="article:tag" content="supervised learning">
<meta property="article:tag" content="support vector machines">
<meta property="article:tag" content="tf-idf">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://redwanhuq.github.io/">

                <span id="blog-title">In Machines We Trust</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../pages/about/">About</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Using natural language processing to build a spam filter for text messages</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Redwan Huq
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2017-05-30T08:00:00-05:00" itemprop="datePublished" title="2017-05-30 08:00">2017-05-30 08:00</time></a></p>
                <p class="commentline">
        
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/post8.html">Comments</a>


            

        </p>
</div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<style type="text/css">
div.prompt {
	display: none;
}

div.rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {
  font-size: 16px;
  border: 1px solid black;
}


</style>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After watching the film <em>Arrival</em>, I developed a deep appreciation for the field of linguistics (also my favorite movie of 2016). Human language is the most unstructured type of data, and yet we effortlessly parse and interpret it, and even generate our own. On the other hand, understanding everyday language is a significant challenge for machines; this is the focus of <strong>natural language processing</strong> (NLP)—the crossroads between linguistics and AI. In this post, we'll make use of some NLP concepts and combine them with machine learning to build a spam filter for SMS text messages.
<!-- TEASER_END --></p>
<p>In the 1950s, Alan Turing conjectured if a machine can fool a human into believing that he/she is speaking with another human, the machine exhibits intelligence—the iconic Turing test. Recently, a machine arguably passed the Turing test <a href="http://www.reading.ac.uk/news-and-events/releases/PR583836.aspx">for the first time</a>; the milestone was largely attributed to advances in NLP. If you've ever wondered how Siri or Google recognizes your voice, makes sense of a semantically nebulous question, such as "How did the Celtics do?", and returns an accurate response, that's also NLP in action! The war on spam is another.</p>
<p>Before Gmail implemented its incredible spam filter, I remember crafting an elaborate set of if/then rules for words typically found in spam. Not surprisingly, it was tedious and prone to mistakes. Nowadays, no one hand codes a spam filter—we train machines to do the job! But email spam is different from SMS message spam; we tend to speak more casually on our phones, using more slang, incomplete sentences, or even concocting words and phrases. Let's see what machine learning can do for SMS message spam.</p>
<h2 id="Table-of-contents">Table of contents<a class="anchor-link" href="#Table-of-contents">¶</a>
</h2>
<ol>
<li><a href="#cell1">Inspecting the dataset</a></li>
<li><a href="#cell2">Text preprocessing</a></li>
<li><a href="#cell3">Feature engineering</a></li>
<li><a href="#cell4">Training and evaluating a model</a></li>
<li><a href="#cell5">What terms are the top predictors of spam?</a></li>
<li><a href="#cell6">How to improve the model</a></li>
</ol>
<p><a id="cell1"></a></p>
<h2 id="1.-Inspecting-the-dataset">1. Inspecting the dataset<a class="anchor-link" href="#1.-Inspecting-the-dataset">¶</a>
</h2>
<p>While browsing the <a href="https://archive.ics.uci.edu/ml/datasets/sms+spam+collection">UCI Machine Learning repository</a>, I discovered a dataset chock-full of anonymous SMS text messages. Let's begin by loading it and taking a look around.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">'data/SMSSpamCollection.txt'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[2]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>0</th>
      <th>1</th>
    </tr></thead>
<tbody>
<tr>
<th>0</th>
      <td>ham</td>
      <td>Go until jurong point, crazy.. Available only ...</td>
    </tr>
<tr>
<th>1</th>
      <td>ham</td>
      <td>Ok lar... Joking wif u oni...</td>
    </tr>
<tr>
<th>2</th>
      <td>spam</td>
      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>
    </tr>
<tr>
<th>3</th>
      <td>ham</td>
      <td>U dun say so early hor... U c already then say...</td>
    </tr>
<tr>
<th>4</th>
      <td>ham</td>
      <td>Nah I don't think he goes to usf, he lives aro...</td>
    </tr>
</tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 5572 entries, 0 to 5571
Data columns (total 2 columns):
0    5572 non-null object
1    5572 non-null object
dtypes: object(2)
memory usage: 87.1+ KB
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have a collection of text data known as a <strong>corpus</strong>. Specifically, there are 5,572 SMS messages written in English, serving as training examples. The first column is the target variable containing the class labels, which tells us if the message is spam or ham (aka not spam). The second column is the SMS message itself, stored as a string.</p>
<p>Since the target variable contains discrete values, this is a classification task. Let's start by placing the target variable in its own table and checking out how the two classes are distributed.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[4]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>ham     4825
spam     747
Name: 0, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It looks like there are far fewer training examples for spam than ham—we'll take this imbalance into account in the analysis. In addition, we need to encode the class labels in the target variable as numbers to ensure compatibility with some models in Scikit-learn. Because we have binary classes, let's use <code>LabelEncoder</code> and set <code>'spam'</code> = <code>1</code> and <code>'ham'</code> = <code>0</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_enc</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, let's place the SMS message data into its own table.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_text</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're sitting on a mountain of text data but it might as well be gibberish since a machine only understands numbers. How can we convert this corpus into useful numerical features so we can train a classifier? This is where NLP comes in.</p>
<p><a id="cell2"></a></p>
<h2 id="2.-Text-preprocessing">2. Text preprocessing<a class="anchor-link" href="#2.-Text-preprocessing">¶</a>
</h2>
<p>There are many feature engineering strategies for transforming text data into features. Some involve assigning each unique word-like term to a feature and counting the number of occurrences per training example. However, if we were to perform this strategy right now, we'd end up with an absurd number of features, a result of the myriad possible terms. The classifier would take too long to train and likely overfit. As a result, <strong>each NLP problem requires a tailored approach to determine which terms are relevant and meaningful</strong>.</p>
<p>For the remainder of this section, I'll walk through my preprocessing strategy, which relies heavily on <a href="http://regexr.com/">regular expressions</a>.</p>
<h3 id="Normalization">Normalization<a class="anchor-link" href="#Normalization">¶</a>
</h3>
<p>Let's begin by taking a step back and examining the terms of a hypothetical SMS message.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example</span> <span class="o">=</span> <span class="s2">"""  ***** CONGRATlations **** You won 2 tIckETs to Hamilton in </span>
<span class="s2">NYC http://www.hamiltonbroadway.com/J?NaIOl/event   wORtH over $500.00...CALL </span>
<span class="s2">555-477-8914 or send message to: hamilton@freetix.com to get ticket !! !  """</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I'd definitely deem this as spam. But clearly there's a lot going on here: phone numbers, emails, website URLs, money amounts, and gratuitous whitespace and punctuation. Some terms are randomly capitalized, others are in all-caps. Since these terms might show up in any one of the training examples in countless forms, we need a way to ensure each training example is on equal footing via a preprocessing step called <strong>normalization</strong>.</p>
<p>Instead of removing the following terms, for each training example, let's replace them with a specific string.</p>
<ul>
<li>Replace email addresses with <code>'emailaddr'</code>
</li>
<li>Replace URLs with <code>'httpaddr'</code>
</li>
<li>Replace money symbols with <code>'moneysymb'</code>
</li>
<li>Replace phone numbers with <code>'phonenumbr'</code>
</li>
<li>Replace numbers with <code>'numbr'</code>
</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">processed</span> <span class="o">=</span> <span class="n">raw_text</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\b[\w\-.]+?@\w+?\.\w{2,4}\b'</span><span class="p">,</span>
                                 <span class="s1">'emailaddr'</span><span class="p">)</span>
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'(http[s]?\S+)|(\w+\.[A-Za-z]{2,4}\S*)'</span><span class="p">,</span>
                                  <span class="s1">'httpaddr'</span><span class="p">)</span>
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'£|\$'</span><span class="p">,</span> <span class="s1">'moneysymb'</span><span class="p">)</span>    
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
    <span class="sa">r</span><span class="s1">'\b(\+\d{1,2}\s)?\d?[\-(.]?\d</span><span class="si">{3}</span><span class="s1">\)?[\s.-]?\d</span><span class="si">{3}</span><span class="s1">[\s.-]?\d</span><span class="si">{4}</span><span class="s1">\b'</span><span class="p">,</span>
    <span class="s1">'phonenumbr'</span><span class="p">)</span>    
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\d+(\.\d+)?'</span><span class="p">,</span> <span class="s1">'numbr'</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we'll remove all punctuation since "today" and "today?" refer to the same word. In addition, let's collapse all whitespace (spaces, line breaks, tabs) into a single space. Furthermore, we'll eliminate any leading or trailing whitespace.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^\w\d\s]'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">r</span><span class="s1">'^\s+|\s+?$'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll also need to treat the words "there", "There" and "ThERe" as the same word. Therefore, let's lowercase the entire corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Removing-stop-words">Removing stop words<a class="anchor-link" href="#Removing-stop-words">¶</a>
</h3>
<p>Some words in the English language, while necessary, don't contribute much to the meaning of a phrase. These words, such as "when", "had", "those" or "before", are called <strong>stop words</strong> and should be filtered out. The Natural Language Toolkit (NLTK), a popular Python library for NLP, provides common stop words.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stop_words</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">'english'</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This list of stop words is literally stored in a Python <code>list</code>. If instead we convert it to a Python <code>set</code>, iterating over the stop words will go <em>much</em> faster, and shave time off this preprocessing step.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">term</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">stop_words</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Stemming">Stemming<a class="anchor-link" href="#Stemming">¶</a>
</h3>
<p>It's likely the corpus contains words with various suffixes such as "distribute", "distributing", "distributor" or "distribution". We can replace these four words with just "distribut" via a preprocessing step called <strong>stemming</strong>. There are numerous stemming strategies, some more aggressive than others. Instead of painstakingly building a stemmer from scratch, let's use one from NLTK called the Porter stemmer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">porter</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">PorterStemmer</span><span class="p">()</span>
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">porter</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Because we have so many preprocessing steps, let's combine them all into a handy function that takes in a string and cleans it up.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">preprocess_text</span><span class="p">(</span><span class="n">messy_string</span><span class="p">):</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">messy_string</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\b[\w\-.]+?@\w+?\.\w{2,4}\b'</span><span class="p">,</span> <span class="s1">'emailaddr'</span><span class="p">,</span> <span class="n">messy_string</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'(http[s]?\S+)|(\w+\.[A-Za-z]{2,4}\S*)'</span><span class="p">,</span> <span class="s1">'httpaddr'</span><span class="p">,</span>
                     <span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'£|\$'</span><span class="p">,</span> <span class="s1">'moneysymb'</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span>
        <span class="sa">r</span><span class="s1">'\b(\+\d{1,2}\s)?\d?[\-(.]?\d</span><span class="si">{3}</span><span class="s1">\)?[\s.-]?\d</span><span class="si">{3}</span><span class="s1">[\s.-]?\d</span><span class="si">{4}</span><span class="s1">\b'</span><span class="p">,</span>
        <span class="s1">'phonenumbr'</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\d+(\.\d+)?'</span><span class="p">,</span> <span class="s1">'numbr'</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^\w\d\s]'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'^\s+|\s+?$'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">cleaned</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">porter</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span> 
        <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">cleaned</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">stop_words</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As a sanity check, let's confirm this function yields the same results as the previous series of steps.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">processed</span> <span class="o">==</span> <span class="n">raw_text</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">preprocess_text</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[15]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Additionally, let's test <code>preprocess_text()</code> on the hypothethical SMS message from earlier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preprocess_text</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[16]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>'congratl numbr ticket hamilton nyc httpaddr worth moneysymbnumbr call phonenumbr send messag emailaddr get ticket'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What a change! It looks like the preprocessing strategy is working. A quick technical note before we move on: since this was the first time I encountered regular expressions, I learned the hard way that mindful usage of the lazy quantifier <code>?</code> is crucial—incorporating it reduced the total preprocessing time from 1 hour to <em>2 seconds!</em></p>
<p><a id="cell3"></a></p>
<h2 id="3.-Feature-engineering">3. Feature engineering<a class="anchor-link" href="#3.-Feature-engineering">¶</a>
</h2>
<p>Now that we've enriched the corpus for meaningful terms, we're ready to construct features. Let's begin by breaking apart the corpus into a vocabulary of unique terms—a process called <strong>tokenization</strong>. However, there are several ways to approach this step.</p>
<h3 id="Tokenization">Tokenization<a class="anchor-link" href="#Tokenization">¶</a>
</h3>
<p>We can tokenize individual terms and generate what's called a <strong>bag of words model</strong>. You may notice this model has a glaring pitfall: it fails to capture the innate structure of human language. Under this model, the following sentences have the same feature vector although they convey dramatically different meanings.</p>
<ul>
<li>Does steak taste delicious?</li>
<li>Steak does taste delicious.</li>
</ul>
<p>Alternatively, we can tokenize every sequence of $n$ terms called $n$-grams. For example, tokenizing adjacent pairs of words yields bigrams. The <strong>$n$-gram model</strong> preserves word order and can potentially capture more information than the bag of words model.</p>
<p>To get the best of both worlds, let's tokenize unigrams <em>and</em> bigrams. As an example, unigrams and bigrams for "The quick brown fox" are "The", "quick", "brown", "fox", "The quick", "quick brown" and "brown fox".</p>
<h3 id="Implementing-the-tf-idf-statistic">Implementing the tf-idf statistic<a class="anchor-link" href="#Implementing-the-tf-idf-statistic">¶</a>
</h3>
<p>Having selected a tokenization strategy, the next step is assign each $n$-gram to a feature and then compute the $n$-gram's frequency using some statistic. Again, we have options.</p>
<p>One statistic called <strong>term frequency (tf)</strong> tallies the occurrences of each $n$-gram for every training example. However, some $n$-grams will undoubtedly show up often in any given SMS message, while others rarely appear in the overall corpus but show up frequently in certain <em>subsets</em> of messages such as spam. Therefore, to emphasize the latter, more interesting set of $n$-grams, we'll downweight the term frequency with <strong>inverse document frequency (idf)</strong>, which is calculated by logarithmically scaling the inverse of the fraction of training examples that contain a given term. Combining these two statistics yields the tf-idf statistic:</p>
$$\textrm{tf-idf}(t, i) = \textrm{tf}(t, i) \times \textrm{idf}(t) \\ = \textrm{tf}(t, i) \times \log\bigg(\frac{M}{m_t}\bigg)$$<p>where $\textrm{tf}(t,i)$ is the term frequency for term $t$ in the $i$th training example, $M$ is the total number of training examples, and $m_t$ is the number of training examples that contain the term $t$.</p>
<p>Scikit-learn has an off-the-shelf tool called <code>TfidfVectorizer</code> that performs $n$-gram tokenization and also computes the tf-idf statistic. Two technical details regarding <code>TfidfVectorizer</code>: a) the tf-idf statistic is computed <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting">slightly differently</a> to avoid division by zero, and b) the computed tf-idf values for each training example are subsequently <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting">normalized</a>.</p>
<p><strong>Finally, we're equipped to transform a corpus of text data into a matrix of numbers with one row per training example and one column per $n$-gram.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">X_ngrams</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">processed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a look at the dimensions of the <code>X_ngrams</code> matrix.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_ngrams</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[18]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>(5572, 36348)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Holy cow, that's one massive matrix! It looks like the tokenization process extracted 36,348 unigrams and bigrams from the corpus; each one defines a feature. Since each training example only makes use of a tiny fraction of the complete $n$-gram vocabulary, <code>X_ngrams</code> mostly consists of zeros and is called a <strong>sparse matrix</strong>. To perform linear algebra computations rapidly on such a large sparse matrix, it'd be more efficient to store only the non-zero values while maintaining the structure. Fortunately, <code>TfidfVectorizer</code> utilizes the SciPy library to do <em>exactly</em> this!</p>
<p><a id="cell4"></a></p>
<h2 id="4.-Training-and-evaluating-a-model">4. Training and evaluating a model<a class="anchor-link" href="#4.-Training-and-evaluating-a-model">¶</a>
</h2>
<p>That was a lot of prep work and we haven't even done any machine learning yet, but all of it crucial for building a robust classifier. <strong>Not only is a model only as good as the data it's trained on, but meticulous feature engineering can beat having a fancy model.</strong> We'll be a training a state of the art classifier called <strong>support vector machines (SVM)</strong>. In a nutshell, this model attempts to find the hyperplane that best separates the two classes.</p>
<p>In particular, I've elected to use SVM with a <em>linear kernel</em> because text data contains a large number of features (we have over 30,000!); using a nonlinear kernel would be <a href="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf">computationally expensive</a>. In addition, text data is typically <a href="https://link.springer.com/chapter/10.1007/BFb0026683">linearly separable to begin with</a>. Finally, we'll use <code>svm.LinearSVC()</code> instead of <code>svm.SVC(kernel='linear')</code> because the former relies on a library whose <a href="https://stackoverflow.com/questions/11508788/whats-the-difference-between-libsvm-and-liblinear">algorithmic complexity</a> is $O(n)$ instead of $O(n^2)$ or $O(n^3)$, meaning much faster.</p>
<h3 id="Preliminary-analysis">Preliminary analysis<a class="anchor-link" href="#Preliminary-analysis">¶</a>
</h3>
<p>For a rudimentary understanding of how well SVM performs on the dataset, let's start with the hold-out method: an 80/20 training and test set split. <strong>Remember to never evaluate a model on the data used to train it!</strong> In addition, since the classes are imbalanced, we'll incorporate stratification and use the $F_1$ score as the performance metric.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_ngrams</span><span class="p">,</span>
    <span class="n">y_enc</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">y_enc</span>
<span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'hinge'</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[19]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>0.9285714285714286</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Not a bad start, but we really need to run cross-validation to gauge whether this performance is consistent. While we're here, let's use a <strong>confusion matrix</strong> to take a peek at what types of mistakes the classifier is making.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
    <span class="n">index</span><span class="o">=</span><span class="p">[[</span><span class="s1">'actual'</span><span class="p">,</span> <span class="s1">'actual'</span><span class="p">],</span> <span class="p">[</span><span class="s1">'spam'</span><span class="p">,</span> <span class="s1">'ham'</span><span class="p">]],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[[</span><span class="s1">'predicted'</span><span class="p">,</span> <span class="s1">'predicted'</span><span class="p">],</span> <span class="p">[</span><span class="s1">'spam'</span><span class="p">,</span> <span class="s1">'ham'</span><span class="p">]]</span>
<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[20]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
<thead>
<tr>
<th></th>
      <th></th>
      <th colspan="2" halign="left">predicted</th>
    </tr>
<tr>
<th></th>
      <th></th>
      <th>spam</th>
      <th>ham</th>
    </tr>
</thead>
<tbody>
<tr>
<th rowspan="2" valign="top">actual</th>
      <th>spam</th>
      <td>965</td>
      <td>1</td>
    </tr>
<tr>
<th>ham</th>
      <td>19</td>
      <td>130</td>
    </tr>
</tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It looks when the classifier does make a mistake, it's typically a false positive:  flagging an SMS message as spam when it's actually not. Not exactly ideal but then again, this is just a single training/test set split.</p>
<h3 id="Diagnosing-the-model-with-learning-curves">Diagnosing the model with learning curves<a class="anchor-link" href="#Diagnosing-the-model-with-learning-curves">¶</a>
</h3>
<p>Because we have so many features, it's prudent to determine whether the classifier suffers from high variance and is overfitting. We can assess the situation by plotting <strong>learning curves</strong>. Here's the procedure:</p>
<ol>
<li>Split the entire dataset $k$ times into a training and validation set</li>
<li>For each split, train the model on <em>subsets</em> of the training set, each with fewer training examples</li>
<li>Evaluate the model on the validation set and each subset of the training set</li>
<li>Average the model performance across the $k$ splits for both training and validation sets</li>
</ol>
<p>Specifically, we'll use 10-fold cross-validation (80/20 split) <em>without regularization</em>. For each fold, we'll train the classifier on 10 different dataset sizes, starting with 500 training examples. Fortunately, Scikit-learn has a convenient tool that computes learning curves in one go.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'int'</span><span class="p">)</span>

<span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">valid_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'hinge'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1e10</span><span class="p">),</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X_ngrams</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_enc</span><span class="p">,</span>
    <span class="n">train_sizes</span><span class="o">=</span><span class="n">sample_space</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">40</span><span class="p">),</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">'f1'</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I love the Seaborn library for visualization but like other high-level plotting libraries, it requires data to be in <a href="https://www.jstatsoft.org/article/view/v059i10">"tidy" format</a> where each variable forms a column and each observation forms a row. Trust me, tidy data make data analysis and plotting <em>so much</em> easier. Let's define a function that combines <code>train_scores</code> and <code>valid_scores</code> into a single tidy table.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">make_tidy</span><span class="p">(</span><span class="n">sample_space</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">valid_scores</span><span class="p">):</span>
    <span class="n">messy_format</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">sample_space</span><span class="p">,</span> <span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="n">valid_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'# of training examples'</span><span class="p">,</span> <span class="s1">'Training set'</span><span class="p">,</span> <span class="s1">'Validation set'</span><span class="p">]</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span>
        <span class="n">messy_format</span><span class="p">,</span>
        <span class="n">id_vars</span><span class="o">=</span><span class="s1">'# of training examples'</span><span class="p">,</span>
        <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'Training set'</span><span class="p">,</span> <span class="s1">'Validation set'</span><span class="p">],</span>
        <span class="n">var_name</span><span class="o">=</span><span class="s1">'Scores'</span><span class="p">,</span>
        <span class="n">value_name</span><span class="o">=</span><span class="s1">'F1 score'</span>
    <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're now ready to use Seaborn to plot learning curves for the classifier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span>
    <span class="n">make_tidy</span><span class="p">(</span><span class="n">sample_space</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">valid_scores</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="s1">'Scores'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>

<span class="n">g</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="s1">'# of training examples'</span><span class="p">,</span> <span class="s1">'F1 score'</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">,</span> <span class="s1">'# of training examples'</span><span class="p">,</span> <span class="s1">'F1 score'</span><span class="p">)</span><span class="o">.</span><span class="n">add_legend</span><span class="p">();</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA6gAAALACAYAAACekV+rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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%0ASuH/AaeGSSn9uI3eAAAAAElFTkSuQmCC" width="468" height="352">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I love learning curves—they're teeming with information! Notice the performance on the training set is near perfect regardless of dataset size, which makes sense because we're evaluating the classifier on the same data used to train it. At first, it looks like the classifier is suffering from high variance and is overfitting since the validation scores never reach the same level. However, taking a closer look at the scale of the $y$-axis makes me believe this issue isn't that pronounced.</p>
<p>Nevertheless, since the validation scores improve with more training examples, an obvious next step is to acquire more data points. In addition, we could try a smaller set of features by only using bigrams, not unigrams. Finally, it's worth tuning the regularization hyperparameter.</p>
<h3 id="Using-nested-cross-validation-to-minimize-information-leakage">Using nested cross-validation to minimize information leakage<a class="anchor-link" href="#Using-nested-cross-validation-to-minimize-information-leakage">¶</a>
</h3>
<p>To optimize hyperparameters, we can use Scikit-learn's <code>GridSearchCV</code> tool, which trains a series of candidate models using every combination of hyperparameters, evaluates each model using $k$-fold cross-validation, and then reports the "winning" model and its hyperparameter combination that yielded the best performance. However, we can't report this value as an unbiased estimate of the model's performance because we repeatedly reused the same data for cross-validation—we potentially "leaked" information across the candidate models!</p>
<p>What we <em>can</em> do is utilize <strong>nested cross-validation</strong> to alleviate this issue. In this procedure, we implement $k$-fold cross-validation to train $k$ models (the outer loop). Using the <em>training set</em> of each fold, we perform <code>GridSearchCV</code> to tune the hyperparameters and select a winning model (the inner loop). Then, using the <em>validation set</em> of each fold, we evaluate the performance of the winning model developed in the inner loop. Finally, by computing the mean of this performance value across the $k$ folds, we can report a robust estimate of the model's performance. This can be a bit confusing so I recommend taking a glance at <a href="https://mlr-org.github.io/mlr-tutorial/devel/html/nested_resampling/index.html">this visual representation</a> of what's going on.</p>
<p>Using nested cross-validation, let's test a range of 20 values for the regularization hyperparameter and use 10-fold cross-validation to assess the classifier's performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">'C'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">)}]</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'hinge'</span><span class="p">),</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">'f1'</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">grid_search</span><span class="p">,</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X_ngrams</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_enc</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">'f1'</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">scores</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[24]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([ 0.91636364,  0.94366197,  0.95104895,  0.93661972,  0.94736842,
        0.93286219,  0.91039427,  0.90510949,  0.9057971 ,  0.94699647])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The scores across the 10 folds demonstrate the classifier's performance is moderately consistent—it depends on what level of variation we're comfortable with. Finally, let's compute the mean score to report an estimate of the classifier's performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[25]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>0.92962222115832238</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id="cell5"></a></p>
<h2 id="5.-What-terms-are-the-top-predictors-of-spam?">5. What terms are the top predictors of spam?<a class="anchor-link" href="#5.-What-terms-are-the-top-predictors-of-spam?">¶</a>
</h2>
<p>I'm incredibly curious about which $n$-grams are the most predictive of spam. But first, we need to use the optimal regularization hyperparameter to train the classifier on the <em>whole</em> dataset in order to provide it as much information as possible.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ngrams</span><span class="p">,</span> <span class="n">y_enc</span><span class="p">)</span>
<span class="n">final_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'hinge'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">'C'</span><span class="p">])</span>
<span class="n">final_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ngrams</span><span class="p">,</span> <span class="n">y_enc</span><span class="p">);</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, let's take a look at the top 20 $n$-grams that are most predictive of spam.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
    <span class="n">final_clf</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[27]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>phonenumbr         5.008632
numbrp             2.799188
txt                2.690817
moneysymbnumbr     2.557430
call phonenumbr    2.251018
rington            2.098571
servic             2.049272
mobil              2.036900
numbr              1.896237
tone               1.831285
repli              1.664237
text               1.603976
claim              1.590065
video              1.473553
free               1.359938
wap                1.336547
stop               1.310738
credit             1.278887
uk                 1.239140
order              1.227617
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are a few obvious ones at the top: <code>phonenumbr</code>, <code>txt</code>, <code>moneysymbnumber</code> (money amount), <code>call phonenumbr</code>, <code>claim</code>, <code>video</code>, <code>free</code>, <code>stop</code>, <code>credit</code> and <code>order</code>. However, the <a href="https://archive.ics.uci.edu/ml/datasets/sms+spam+collection">data description</a> points out the majority of the spam in this dataset originated from a British website, while the most of the ham came from Singaporean students. This is quite concerning because the lexicon in SMS messages varies dramatically across different national, cultural and age demographics. This sampling bias may adversely affect the validity of the classifier. Remember what I said earlier about the data you use to train a model?</p>
<p>To finish up, let's write up a function that'll decide whether a string is spam or not, and apply it on the hypothetical message from earlier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">spam_filter</span><span class="p">(</span><span class="n">message</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">final_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="n">preprocess_text</span><span class="p">(</span><span class="n">message</span><span class="p">)])):</span>
        <span class="k">return</span> <span class="s1">'spam'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">'not spam'</span>
</pre></div>

</div>
</div>
</div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spam_filter</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[29]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>'spam'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The classifier decided that message was indeed spam. Do you agree? Let's try a real SMS message that I just received (spoiler: it's not spam).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input_hidden">
<div class="input">
<div class="prompt input_prompt">In [30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spam_filter</span><span class="p">(</span><span class="s1">'Ohhh, but those are the best kind of foods'</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[30]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>'not spam'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Cool! Go ahead and try your own messages!</p>
<p><a id="cell6"></a></p>
<h2 id="6.-How-to-improve-the-model">6. How to improve the model<a class="anchor-link" href="#6.-How-to-improve-the-model">¶</a>
</h2>
<p>We can attempt to boost the classifier's performance but there's simply too many different avenues. However, I'd like to highlight some of the prominent ones.</p>
<ol>
<li>Text preprocessing<ul>
<li>I handcrafted the regular expressions in this post (by no means an expert!) but I'm certain we can increase their matching performance and efficiency. It may be also be worthwhile using regex to normalize other terms such as dates, times, slang, etc.</li>
<li>I selected the Porter stemmer here but comparing the performance with the Lancaster stemmer would be interesting. However, stemming can be crude and chop off suffixes haphazhardly—a better alternative is <strong>lemmatization</strong>. For example, the word "worse" reduces to "bad".</li>
<li>We ignored the innate features of each training example such as message length, average word length, distribution of the various forms of punctuation, all-caps frequency, etc. Each of these may enhance the classifier's predictive capacity.</li>
</ul>
</li>
<li>Feature engineering<ul>
<li>I discovered Scikit-learn computes term frequency by simply counting each term. Because SMS messages come in a variety of lengths, normalizing the term frequency to the message length is a good idea.</li>
<li>You may have noticed most of the top 20 terms listed above are unigrams. This hints that bigrams aren't as useful in this problem—a bag of words model may be sufficient.</li>
</ul>
</li>
<li>Machine learning<ul>
<li>Instead of tuning just the classifier's hyperparameters, we can perform a more exhaustive <code>GridSearchCV</code> to compare the use of raw term frequencies instead of tf-idf, or perhaps only tokenizing terms that have a term frequency above/below a threshold. In fact, <code>TfidfVectorizer</code> includes many other knobs to play with. In addition, we can test other classifiers such as Naive Bayes, logistic regression or a neural net. All of these different options can be investigated simultaneously by combining <code>GridSearchCV</code> with Scikit-learn's <a href="http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html"><code>Pipeline</code> tool</a>.</li>
</ul>
</li>
</ol>
<p>Of course, the biggest issue in this analysis stems from the dataset itself. We discovered the training examples weren't <strong>independently and identically distributed</strong>, which breaks an <a href="https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning">important assumption</a> in machine learning. Therefore, to improve the classifier, it's crucial to not only acquire <em>more</em> training examples but ensure they all come from the same distribution.</p>
<p>You probably realized by now that each time you reported an email as spam on Gmail, you were providing Google one more training example to help improve their classifier! I hope this post presented a glimpse of what NLP offers and how it can be combined with machine learning to tackle a real world problem. I've only scratched the surface—can't wait to dive deeper into the linguistics!</p>
<p>If you'd like to play around with the code, here's the <a href="https://github.com/redwanhuq/machine-learning">GitHub repo</a>. As always, don't hesitate to leave your comments below.</p>

</div>
</div>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/classification/" rel="tag">classification</a></li>
            <li><a class="tag p-category" href="../../categories/learning-curves/" rel="tag">learning curves</a></li>
            <li><a class="tag p-category" href="../../categories/machine-learning/" rel="tag">machine learning</a></li>
            <li><a class="tag p-category" href="../../categories/n-grams/" rel="tag">n-grams</a></li>
            <li><a class="tag p-category" href="../../categories/natural-language-processing/" rel="tag">natural language processing</a></li>
            <li><a class="tag p-category" href="../../categories/nested-cross-validation/" rel="tag">nested cross-validation</a></li>
            <li><a class="tag p-category" href="../../categories/nltk/" rel="tag">nltk</a></li>
            <li><a class="tag p-category" href="../../categories/scikit-learn/" rel="tag">scikit-learn</a></li>
            <li><a class="tag p-category" href="../../categories/supervised-learning/" rel="tag">supervised learning</a></li>
            <li><a class="tag p-category" href="../../categories/support-vector-machines/" rel="tag">support vector machines</a></li>
            <li><a class="tag p-category" href="../../categories/tf-idf/" rel="tag">tf-idf</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../mushroom-classification/" rel="prev" title="Determining whether a mushroom is edible with machine learning">Previous post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
        
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="machinemade",
            disqus_url="https://redwanhuq.github.io/posts/sms-spam-filter/",
        disqus_title="Using natural language processing to build a spam filter for text messages",
        disqus_identifier="cache/posts/post8.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article><script>var disqus_shortname="machinemade";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        <!--End of body content-->

        <footer id="footer"><div class="text-center">
<p>
<span class="fa-stack fa-2x">
  <a href="../../rss.xml">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-rss fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://twitter.com/redwanhuq">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-twitter fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://github.com/redwanhuq">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-github fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://www.linkedin.com/in/redwanhuq">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-linkedin fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="mailto:redwanhuq@gmail.com">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-envelope fa-inverse fa-stack-1x"></i>
  </a>
</span>
</p>
<p>
  Contents © 2017  <a href="mailto:redwanhuq@gmail.com">Redwan Huq</a>
  
  —
  Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
</p>
</div>

            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(2, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90799006-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
